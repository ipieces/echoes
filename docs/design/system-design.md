# Audio Journal â€” ä¸ªäººå…¨å¤©å€™å½•éŸ³åˆ†æç³»ç»Ÿ

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** å°†æ¯æ—¥ä½©æˆ´å½•éŸ³è®¾å¤‡é‡‡é›†çš„é•¿æ—¶é—´éŸ³é¢‘ï¼Œè‡ªåŠ¨è½¬å†™ã€æ™ºèƒ½åˆ†æ®µã€åœºæ™¯åˆ†ç±»ã€å†…å®¹åˆ†æï¼Œç»ç”¨æˆ· CLI ç¡®è®¤åå½’æ¡£åˆ°æœ¬åœ°æˆ– Obsidianã€‚

**Architecture:** å…¨è‡ªåŠ¨åå°æœåŠ¡ + ç®¡ç† CLIã€‚æ–‡ä»¶ç›‘å¬å™¨æ£€æµ‹æ–°å½•éŸ³åè‡ªåŠ¨è§¦å‘å®Œæ•´ Pipelineï¼šéŸ³é¢‘é¢„åˆ‡åˆ† â†’ æœ¬åœ° ASRï¼ˆå«è¯´è¯äººè¯†åˆ«ï¼‰â†’ æ–‡æœ¬åˆ†æ®µ â†’ åœºæ™¯åˆ†ç±» â†’ åœºæ™¯ä¸“ç”¨åˆ†æ â†’ è‡ªåŠ¨å½’æ¡£ã€‚æ— éœ€äººå·¥ç¡®è®¤ï¼Œé€šè¿‡æŒç»­ä¼˜åŒ– prompt å’Œå‚æ•°æå‡è´¨é‡ã€‚

**Tech Stack:** Python 3.11+, æœ¬åœ° ASR (FunASR/WhisperX + diarization), äº‘ç«¯ LLM API (å¤šæ¨¡å‹æŠ½è±¡å±‚), Click (CLI), Pydantic (æ•°æ®æ¨¡å‹), watchdog (æ–‡ä»¶ç›‘å¬)

---

## 1. ç³»ç»Ÿæ¶æ„

### 1.1 æ•´ä½“æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Watcher â”‚â”€â”€â”€â–¶â”‚  WAV     â”‚â”€â”€â”€â–¶â”‚ éŸ³é¢‘é¢„åˆ‡åˆ†â”‚â”€â”€â”€â–¶â”‚  ASR    â”‚â”€â”€â”€â–¶â”‚  åˆ†æ®µå™¨  â”‚â”€â”€â”€â–¶â”‚ åœºæ™¯åˆ†ç±»  â”‚â”€â”€â”€â–¶â”‚ åˆ†æAgent â”‚â”€â”€â”€â–¶â”‚ è‡ªåŠ¨å½’æ¡£ â”‚
â”‚ æ–‡ä»¶ç›‘å¬ â”‚    â”‚  éŸ³é¢‘    â”‚    â”‚ Chunker  â”‚    â”‚ +è¯´è¯äºº  â”‚    â”‚Segmenterâ”‚    â”‚ Router   â”‚    â”‚ Analyzer â”‚    â”‚ Archive â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### é•¿å½•éŸ³é¢„åˆ‡åˆ†ç­–ç•¥

é•¿æ—¶é—´å½•éŸ³ï¼ˆæ•°å°æ—¶ï¼‰ä¸èƒ½ç›´æ¥å–‚ç»™ ASR + è¯´è¯äººè¯†åˆ«æ¨¡å‹ï¼ŒåŸå› ï¼š
1. **å†…å­˜çˆ†ç‚¸** â€” å¤§å¤šæ•° diarization æ¨¡å‹è®¾è®¡ç”¨äº 30min-2h éŸ³é¢‘
2. **è¯´è¯äººæ¼‚ç§»** â€” åŒä¸€äººæ—©æ™šå£°çº¹ç‰¹å¾æœ‰å·®å¼‚ï¼Œé•¿éŸ³é¢‘è¯†åˆ«å‡†ç¡®åº¦ä¸‹é™
3. **è·¨æ®µä¸ä¸€è‡´** â€” åˆ†å—å¤„ç†æ—¶ speaker ID åœ¨ä¸åŒå—é—´ä¸ä¸€è‡´

**è§£å†³æ–¹æ¡ˆï¼šéŸ³é¢‘çº§é¢„åˆ‡åˆ†ï¼ˆChunkerï¼‰**

åœ¨ ASR ä¹‹å‰ï¼Œå…ˆç”¨ VADï¼ˆè¯­éŸ³æ´»åŠ¨æ£€æµ‹ï¼‰æŒ‰é•¿é™éŸ³é—´éš”å°†åŸå§‹ WAV åˆ‡æˆ 10 åˆ†é’Ÿ - 4 å°æ—¶çš„ chunkï¼Œæ¯ä¸ª chunk ç‹¬ç«‹èµ°å®Œæ•´ pipelineï¼š

```
åŸå§‹ WAV (8h)
  â†“ éŸ³é¢‘é¢„åˆ‡åˆ† (VAD/é™éŸ³æ£€æµ‹, å¯é…ç½®é™éŸ³é˜ˆå€¼)
  â†“
chunk_001.wav (3h 15m) â†’ ASR+è¯´è¯äºº â†’ åˆ†æ®µ â†’ åˆ†ç±» â†’ åˆ†æ
chunk_002.wav (2h 30m) â†’ ASR+è¯´è¯äºº â†’ åˆ†æ®µ â†’ åˆ†ç±» â†’ åˆ†æ
chunk_003.wav (1h 45m) â†’ ASR+è¯´è¯äºº â†’ åˆ†æ®µ â†’ åˆ†ç±» â†’ åˆ†æ
...
  â†“
æ‰€æœ‰åˆ†æç»“æœæ±‡æ€» â†’ è‡ªåŠ¨å½’æ¡£
```

**ä¼˜åŠ¿ï¼š**
- å†…å­˜å¯æ§ï¼Œæ¯æ¬¡åªå¤„ç†ä¸€ä¸ª chunk
- å„ chunk å¯å¹¶è¡Œå¤„ç†ï¼ŒåŠ é€Ÿæ•´ä½“æµç¨‹
- è¯´è¯äººè¯†åˆ«åœ¨ chunk ç²’åº¦ä¸Šå‡†ç¡®åº¦é«˜

**ä»£ä»·ï¼š**
- è·¨ chunk çš„è¯´è¯äººå…³è”ï¼ˆ"chunk1 çš„ SPEAKER_01 å’Œ chunk3 çš„ SPEAKER_02 æ˜¯åŒä¸€ä¸ªäºº"ï¼‰åœ¨ MVP é˜¶æ®µä¸åšï¼Œä½œä¸º Phase 3 ä¼˜åŒ–é¡¹
- å¦‚æœä¸€æ®µå¯¹è¯åˆšå¥½è·¨åˆ‡åˆ†ç‚¹ä¼šè¢«æ‹†æˆä¸¤æ®µï¼ˆä½†é¢„åˆ‡åˆ†æŒ‰é•¿é™éŸ³åˆ‡ï¼Œæ­£å¸¸å¯¹è¯ä¸­ä¸å¤ªä¼šæœ‰è¶…è¿‡é˜ˆå€¼çš„é™éŸ³ï¼Œè¯¯åˆ‡æ¦‚ç‡å¾ˆä½ï¼‰

### 1.2 ç›®å½•ç»“æ„

```
audio-journal/
â”œâ”€â”€ pyproject.toml              # é¡¹ç›®é…ç½® (ä½¿ç”¨ uv/poetry)
â”œâ”€â”€ config.yaml                 # è¿è¡Œæ—¶é…ç½®ï¼ˆASRæ¨¡å‹ã€LLM API keysã€åœºæ™¯å®šä¹‰ç­‰ï¼‰
â”œâ”€â”€ src/
â”‚   â””â”€â”€ audio_journal/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cli.py              # CLI å…¥å£ (Click)
â”‚       â”œâ”€â”€ config.py           # é…ç½®åŠ è½½ (Pydantic Settings)
â”‚       â”œâ”€â”€ pipeline.py         # Pipeline ç¼–æ’å™¨
â”‚       â”œâ”€â”€ watcher/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ file_watcher.py # æ–‡ä»¶ç›‘å¬æœåŠ¡ (watchdog)
â”‚       â”œâ”€â”€ chunker/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ vad_chunker.py  # åŸºäº VAD/é™éŸ³æ£€æµ‹çš„éŸ³é¢‘é¢„åˆ‡åˆ†
â”‚       â”œâ”€â”€ asr/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py         # ASR æŠ½è±¡åŸºç±»
â”‚       â”‚   â”œâ”€â”€ funasr.py       # FunASR å®ç°
â”‚       â”‚   â””â”€â”€ whisperx.py     # WhisperX å®ç°
â”‚       â”œâ”€â”€ segmenter/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ silence.py      # åŸºäºé™éŸ³/æ—¶é—´é—´éš”çš„åˆ†æ®µå™¨
â”‚       â”œâ”€â”€ classifier/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ scene.py        # åœºæ™¯åˆ†ç±»å™¨ (LLM-based)
â”‚       â”œâ”€â”€ analyzer/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py         # åˆ†æå™¨æŠ½è±¡åŸºç±»
â”‚       â”‚   â”œâ”€â”€ meeting.py      # å·¥ä½œä¼šè®®åˆ†æ
â”‚       â”‚   â”œâ”€â”€ business.py     # å•†åŠ¡æ‹œè®¿åˆ†æ
â”‚       â”‚   â”œâ”€â”€ idea.py         # çµæ„Ÿ/è‡ªè¨€è‡ªè¯­åˆ†æ
â”‚       â”‚   â”œâ”€â”€ learning.py     # å­¦ä¹ /è§†é¢‘åˆ†æ
â”‚       â”‚   â”œâ”€â”€ phone.py        # ç”µè¯é€šè¯åˆ†æ
â”‚       â”‚   â””â”€â”€ chat.py         # é—²èŠåˆ†æï¼ˆå«ä»·å€¼æ£€æµ‹ï¼‰
â”‚       â”œâ”€â”€ llm/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py         # LLM Provider æŠ½è±¡åŸºç±» + å·¥å‚
â”‚       â”‚   â””â”€â”€ openai_compat.py# OpenAI Chat Completions å…¼å®¹å®ç°ï¼ˆopenai/deepseek/z.aiï¼‰
â”‚       â”œâ”€â”€ archiver/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ local.py        # æœ¬åœ°æ–‡ä»¶å½’æ¡£
â”‚       â”‚   â””â”€â”€ obsidian.py     # Obsidian vault å½’æ¡£
â”‚       â””â”€â”€ models/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â””â”€â”€ schemas.py      # Pydantic æ•°æ®æ¨¡å‹
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ classifier.txt          # åœºæ™¯åˆ†ç±» prompt
â”‚   â”œâ”€â”€ meeting.txt             # å·¥ä½œä¼šè®®åˆ†æ prompt
â”‚   â”œâ”€â”€ business.txt            # å•†åŠ¡æ‹œè®¿åˆ†æ prompt
â”‚   â”œâ”€â”€ idea.txt                # çµæ„Ÿåˆ†æ prompt
â”‚   â”œâ”€â”€ learning.txt            # å­¦ä¹ åˆ†æ prompt
â”‚   â”œâ”€â”€ phone.txt               # ç”µè¯é€šè¯åˆ†æ prompt
â”‚   â””â”€â”€ chat.txt                # é—²èŠåˆ†æ prompt (å«ä»·å€¼æ£€æµ‹)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ inbox/                  # å¾…å¤„ç†çš„ WAV æ–‡ä»¶æ”¾è¿™é‡Œ
â”‚   â”œâ”€â”€ processing/             # å¤„ç†ä¸­çš„ä¸­é—´æ–‡ä»¶
â”‚   â”œâ”€â”€ transcripts/            # ASR è½¬å†™ç»“æœ
â”‚   â”œâ”€â”€ analysis/               # åˆ†æç»“æœï¼ˆå¾…ç¡®è®¤ï¼‰
â”‚   â””â”€â”€ archive/                # å·²ç¡®è®¤å½’æ¡£çš„æœ¬åœ°æ–‡ä»¶
â””â”€â”€ tests/
    â”œâ”€â”€ test_segmenter.py
    â”œâ”€â”€ test_classifier.py
    â”œâ”€â”€ test_analyzer.py
    â””â”€â”€ test_pipeline.py
```

---

## 2. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 2.1 æ•°æ®æ¨¡å‹ (`models/schemas.py`)

```python
from pydantic import BaseModel
from enum import Enum
from datetime import datetime

class SceneType(str, Enum):
    MEETING = "meeting"           # å·¥ä½œä¼šè®®
    BUSINESS = "business"         # å•†åŠ¡æ‹œè®¿
    IDEA = "idea"                 # çµæ„Ÿ/è‡ªè¨€è‡ªè¯­
    LEARNING = "learning"         # å­¦ä¹ /è§‚çœ‹è§†é¢‘
    PHONE = "phone"               # ç”µè¯é€šè¯
    CHAT = "chat"                 # æœ‹å‹é—²èŠ

class Speaker(BaseModel):
    id: str                       # è¯´è¯äººæ ‡è¯† (SPEAKER_00, SPEAKER_01...)
    label: str | None = None      # ç”¨æˆ·æ ‡æ³¨çš„åå­—ï¼ˆå¯é€‰ï¼‰

class Utterance(BaseModel):
    """ASR è½¬å†™çš„å•æ¡å‘è¨€"""
    speaker: Speaker
    text: str
    start_time: float             # ç§’
    end_time: float               # ç§’

class Segment(BaseModel):
    """åˆ†æ®µåçš„ä¸€ä¸ªç‰‡æ®µ"""
    id: str                       # å”¯ä¸€æ ‡è¯†
    utterances: list[Utterance]
    start_time: float
    end_time: float
    duration: float               # ç§’
    source_file: str              # åŸå§‹ WAV æ–‡ä»¶å

class ClassifiedSegment(Segment):
    """åˆ†ç±»åçš„ç‰‡æ®µ"""
    scene: SceneType
    confidence: float             # åˆ†ç±»ç½®ä¿¡åº¦
    value_tags: list[str] = []    # ä»·å€¼æ ‡ç­¾ï¼ˆæŠ•èèµ„/æŠ€æœ¯/å¸‚åœºç­‰ï¼‰

class AnalysisResult(BaseModel):
    """åˆ†æç»“æœ"""
    segment_id: str
    scene: SceneType
    summary: str                  # æ‘˜è¦
    key_points: list[str]         # å…³é”®è¦ç‚¹
    action_items: list[str] = []  # å¾…åŠäº‹é¡¹ï¼ˆä¼šè®®/å•†åŠ¡åœºæ™¯ï¼‰
    participants: list[str] = []  # å‚ä¸è€…
    topics: list[str] = []       # è¯é¢˜æ ‡ç­¾
    value_level: str = "normal"   # high / normal / low
    raw_text: str                 # åŸå§‹è½¬å†™æ–‡æœ¬
    metadata: dict = {}           # åœºæ™¯ç‰¹å®šçš„é¢å¤–å­—æ®µ

class ReviewDecision(str, Enum):
    ACCEPT = "accept"             # ç¡®è®¤å½’æ¡£
    EDIT = "edit"                 # ç¼–è¾‘åå½’æ¡£
    SKIP = "skip"                 # è·³è¿‡ï¼ˆä¸å½’æ¡£ï¼‰
    DISCARD = "discard"           # ä¸¢å¼ƒ

class ArchiveTarget(str, Enum):
    LOCAL = "local"               # æœ¬åœ° markdown
    OBSIDIAN = "obsidian"         # Obsidian vault
```

### 2.2 ASR æ¨¡å— (`asr/`)

æŠ½è±¡åŸºç±»ï¼š

```python
class ASREngine(ABC):
    @abstractmethod
    def transcribe(self, audio_path: str) -> list[Utterance]:
        """è½¬å†™éŸ³é¢‘æ–‡ä»¶ï¼Œè¿”å›å¸¦è¯´è¯äººæ ‡ç­¾å’Œæ—¶é—´æˆ³çš„å‘è¨€åˆ—è¡¨"""
        ...
```

ä¸¤ä¸ªå®ç°ï¼š
- `FunASREngine` â€” é˜¿é‡Œè¾¾æ‘©é™¢ FunASRï¼ŒåŸç”Ÿæ”¯æŒä¸­æ–‡ + è¯´è¯äººè¯†åˆ«ï¼Œæ¨èé¦–é€‰
- `WhisperXEngine` â€” WhisperX + pyannoteï¼Œè‹±æ–‡æ›´å¼ºï¼Œä¸­æ–‡éœ€è¦é¢å¤–è°ƒä¼˜

é…ç½®é€‰æ‹©å“ªä¸ªå¼•æ“ï¼š

```yaml
asr:
  engine: funasr          # funasr | whisperx
  model: paraformer-zh    # ASR æ¨¡å‹
  device: mps             # mps (Apple Silicon) | cpu | cuda
  batch_size: 4
  language: zh
```

### 2.3 åˆ†æ®µå™¨ (`segmenter/`)

åŸºäºé™éŸ³é—´éš” + æ—¶é—´çª—å£çš„åˆ†æ®µç­–ç•¥ï¼š

```python
class SilenceSegmenter:
    def __init__(self, config: SegmenterConfig):
        self.min_silence_gap: float = 30.0    # è¶…è¿‡30ç§’é™éŸ³è§†ä¸ºåˆ†æ®µç‚¹
        self.max_segment_duration: float = 1800.0  # å•æ®µæœ€é•¿30åˆ†é’Ÿ
        self.min_segment_duration: float = 10.0    # ä½äº10ç§’çš„æ®µä¸¢å¼ƒ

    def segment(self, utterances: list[Utterance], source_file: str) -> list[Segment]:
        """å°†è¿ç»­çš„å‘è¨€æŒ‰é™éŸ³é—´éš”åˆ‡åˆ†ä¸ºç‹¬ç«‹ç‰‡æ®µ"""
        ...
```

åˆ†æ®µé€»è¾‘ï¼š
1. éå† utterancesï¼Œè®¡ç®—ç›¸é‚»å‘è¨€çš„æ—¶é—´é—´éš”
2. é—´éš” > `min_silence_gap` â†’ åˆ‡åˆ†
3. å•æ®µç´¯è®¡æ—¶é•¿ > `max_segment_duration` â†’ å¼ºåˆ¶åˆ‡åˆ†ï¼ˆåœ¨æœ€è¿‘çš„é™éŸ³ç‚¹ï¼‰
4. è¿‡æ»¤æ‰æ—¶é•¿ < `min_segment_duration` çš„ç¢ç‰‡æ®µ

### 2.4 åœºæ™¯åˆ†ç±»å™¨ (`classifier/`)

ä¸¤å±‚åˆ†ç±»æ¶æ„ï¼š

```python
class SceneClassifier:
    async def classify(self, segment: Segment) -> ClassifiedSegment:
        """
        ç¬¬ä¸€å±‚ï¼šåœºæ™¯åˆ†ç±» â€” åˆ¤æ–­å±äº6ä¸ªåœºæ™¯ä¸­çš„å“ªä¸ª
        ç¬¬äºŒå±‚ï¼šä»·å€¼æ£€æµ‹ â€” å¯¹é—²èŠåœºæ™¯ï¼Œæ‰«ææ˜¯å¦åŒ…å«é«˜ä»·å€¼è¯é¢˜
        """
        # 1. æå–ç‰‡æ®µçš„å‰Næ¡å‘è¨€ä½œä¸ºæ ·æœ¬
        sample_text = self._extract_sample(segment)

        # 2. è°ƒç”¨ LLM è¿›è¡Œåœºæ™¯åˆ†ç±»
        scene, confidence = await self._classify_scene(sample_text)

        # 3. å¦‚æœæ˜¯é—²èŠåœºæ™¯ï¼Œè¿›è¡Œä»·å€¼æ£€æµ‹
        value_tags = []
        if scene == SceneType.CHAT:
            value_tags = await self._detect_value(sample_text)

        return ClassifiedSegment(
            **segment.model_dump(),
            scene=scene,
            confidence=confidence,
            value_tags=value_tags,
        )
```

åˆ†ç±» prompt è®¾è®¡è¦ç‚¹ï¼ˆ`prompts/classifier.txt`ï¼‰ï¼š

```
ä½ æ˜¯ä¸€ä¸ªéŸ³é¢‘å†…å®¹åœºæ™¯åˆ†ç±»å™¨ã€‚æ ¹æ®ä»¥ä¸‹è½¬å†™æ–‡æœ¬ç‰‡æ®µï¼Œåˆ¤æ–­å®ƒå±äºå“ªä¸ªåœºæ™¯ï¼š

1. meeting â€” å·¥ä½œä¼šè®®ï¼ˆå¤šäººè®¨è®ºå·¥ä½œäº‹é¡¹ã€é¡¹ç›®è¿›å±•ã€æŠ€æœ¯æ–¹æ¡ˆï¼‰
2. business â€” å•†åŠ¡æ‹œè®¿ï¼ˆå®¢æˆ·/ä¾›åº”å•†/æ¸ é“/åˆä½œæ–¹çš„æ­£å¼æˆ–åŠæ­£å¼äº¤æµï¼‰
3. idea â€” çµæ„Ÿ/è‡ªè¨€è‡ªè¯­ï¼ˆä¸ªäººæ€è€ƒã€çµæ„Ÿè®°å½•ã€è‡ªæˆ‘å¯¹è¯ï¼‰
4. learning â€” å­¦ä¹ /è§‚çœ‹è§†é¢‘ï¼ˆå¬è¯¾ã€çœ‹è§†é¢‘ã€é˜…è¯»è®¨è®ºï¼‰
5. phone â€” ç”µè¯é€šè¯ï¼ˆç”µè¯äº¤æµï¼Œé€šå¸¸åªæœ‰ä¸¤ä¸ªè¯´è¯äººï¼‰
6. chat â€” æœ‹å‹é—²èŠï¼ˆéå·¥ä½œçš„ç¤¾äº¤å¯¹è¯ï¼‰

åˆ¤æ–­ä¾æ®ï¼šè¯´è¯äººæ•°é‡ã€å¯¹è¯è¯­æ°”ã€å†…å®¹ä¸»é¢˜ã€æ­£å¼ç¨‹åº¦ã€‚

è¾“å‡º JSONï¼š
{"scene": "<scene_type>", "confidence": 0.0-1.0, "reasoning": "ç®€çŸ­ç†ç”±"}
```

ä»·å€¼æ£€æµ‹ promptï¼ˆé—²èŠåœºæ™¯ä¸“ç”¨ï¼‰ï¼š

```
ä»¥ä¸‹æ˜¯ä¸€æ®µé—²èŠå¯¹è¯ã€‚è¯·æ£€æµ‹å…¶ä¸­æ˜¯å¦åŒ…å«ä»¥ä¸‹é«˜ä»·å€¼è¯é¢˜ï¼š
- æŠ•èèµ„ä¿¡æ¯ï¼ˆèèµ„ã€æŠ•èµ„ã€ä¼°å€¼ã€ä¸Šå¸‚ï¼‰
- æŠ€æœ¯è®¨è®ºï¼ˆæ¶æ„ã€ç®—æ³•ã€æ–°æŠ€æœ¯ã€å·¥å…·ï¼‰
- å¸‚åœºè§£è¯»ï¼ˆè¡Œä¸šè¶‹åŠ¿ã€ç«äº‰åˆ†æã€å¸‚åœºæœºä¼šï¼‰
- äººè„‰ä¿¡æ¯ï¼ˆå…³é”®äººç‰©ã€ç»„ç»‡å˜åŠ¨ã€åˆä½œæœºä¼šï¼‰
- å•†ä¸šæ´å¯Ÿï¼ˆå•†ä¸šæ¨¡å¼ã€ç›ˆåˆ©ç­–ç•¥ã€æˆæœ¬åˆ†æï¼‰

å¦‚æœåŒ…å«ï¼Œè¾“å‡ºç›¸å…³æ ‡ç­¾ï¼›å¦‚æœçº¯é—²èŠæ— ä»·å€¼å†…å®¹ï¼Œè¾“å‡ºç©ºåˆ—è¡¨ã€‚

è¾“å‡º JSONï¼š
{"value_tags": ["tag1", "tag2"], "has_value": true/false}
```

### 2.5 åœºæ™¯åˆ†æå™¨ (`analyzer/`)

æ¯ä¸ªåœºæ™¯å¯¹åº”ä¸€ä¸ªä¸“ç”¨åˆ†æå™¨ï¼Œå…±äº«æŠ½è±¡åŸºç±»ï¼š

```python
class BaseAnalyzer(ABC):
    def __init__(self, llm: LLMProvider, prompt_path: str):
        self.llm = llm
        self.prompt = self._load_prompt(prompt_path)

    @abstractmethod
    async def analyze(self, segment: ClassifiedSegment) -> AnalysisResult:
        ...
```

å„åœºæ™¯åˆ†æå™¨çš„è¾“å‡ºé‡ç‚¹ï¼š

| åœºæ™¯ | æ ¸å¿ƒè¾“å‡º | é¢å¤–å­—æ®µ |
|------|---------|---------|
| meeting | å†³ç­–ã€å¾…åŠã€è´£ä»»äººã€æ—¶é—´èŠ‚ç‚¹ | `decisions`, `deadlines` |
| business | å…³é”®è¯‰æ±‚ã€æ‰¿è¯ºã€è·Ÿè¿›äº‹é¡¹ | `commitments`, `follow_ups` |
| idea | æ ¸å¿ƒæƒ³æ³•ã€ä¸»é¢˜æ ‡ç­¾ | `idea_type` (çµæ„Ÿ/åæ€/è®¡åˆ’) |
| learning | çŸ¥è¯†ç‚¹æ‘˜è¦ã€ä¸ªäººç¬”è®° | `source_type` (è§†é¢‘/è¯¾ç¨‹/é˜…è¯») |
| phone | å¯¹æ–¹è¯‰æ±‚ã€çº¦å®šäº‹é¡¹ | `caller_intent` |
| chat | é«˜ä»·å€¼ç‰‡æ®µæå– | `value_tags`, `extracted_insights` |

Router é€»è¾‘ï¼š

```python
class AnalyzerRouter:
    def __init__(self, analyzers: dict[SceneType, BaseAnalyzer]):
        self.analyzers = analyzers

    async def route(self, segment: ClassifiedSegment) -> AnalysisResult:
        analyzer = self.analyzers[segment.scene]
        return await analyzer.analyze(segment)
```

### 2.6 LLM æŠ½è±¡å±‚ (`llm/`)

```python
class LLMProvider(ABC):
    @abstractmethod
    async def complete(self, prompt: str, system: str = "", json_mode: bool = False) -> str:
        ...

class LLMFactory:
    """æ ¹æ®é…ç½®åˆ›å»º Providerï¼Œå¹¶æ”¯æŒæŒ‰ stage è¦†ç›–ã€‚"""

    @staticmethod
    def create(cfg: LLMConfig, stage: str | None = None) -> LLMProvider:
        eff = getattr(cfg.overrides, stage, None) if stage else None
        eff = eff or cfg
        provider = eff.provider

        # Phase 1 MVP: ä»…å®ç° OpenAI Chat Completions å…¼å®¹åè®®ï¼ˆOpenAI/DeepSeek/z.aiï¼‰ã€‚
        if provider in {"openai", "deepseek", "zai"}:
            return OpenAICompatibleProvider(...)

        # å¦‚æœ stage override æŒ‡å®šäº†æœªå®ç° providerï¼ˆä¾‹å¦‚ claudeï¼‰ï¼Œå›é€€åˆ°ä¸»é…ç½®ã€‚
        ...
```

é…ç½®ï¼š

```yaml
llm:
  provider: deepseek        # openai | deepseek | zai
  model: deepseek-chat      # å…·ä½“æ¨¡å‹å
  api_key_env: DEEPSEEK_API_KEY  # ä»ç¯å¢ƒå˜é‡è¯»å–ï¼ˆz.ai æ¨è ZHIPUAI_API_KEYï¼‰
  # base_url: https://api.deepseek.com/v1  # å¯é€‰ï¼šä¸å¡«ä½¿ç”¨å†…ç½®é»˜è®¤å€¼ï¼›zai é»˜è®¤ https://open.bigmodel.cn/api/paas/v4/
  temperature: 0.3
  max_tokens: 4096

  # å¯é€‰ï¼šä¸åŒé˜¶æ®µç”¨ä¸åŒæ¨¡å‹
  overrides:
    classifier:
      provider: deepseek
      model: deepseek-chat   # åˆ†ç±»ç”¨ä¾¿å®œå¿«é€Ÿçš„æ¨¡å‹
    analyzer:
      provider: zai
      model: glm-4-plus
      api_key_env: ZHIPUAI_API_KEY
```

### 2.7 CLI ç¡®è®¤ (`reviewer/`)

```
$ audio-journal review

ğŸ“… 2026-02-26 å½•éŸ³åˆ†æç»“æœ (12 ä¸ªç‰‡æ®µ)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[1/12] ğŸ¢ å·¥ä½œä¼šè®® | 09:15-10:32 (1h17m) | ç½®ä¿¡åº¦: 0.95
è¯´è¯äºº: SPEAKER_00 (ä½ ), SPEAKER_01, SPEAKER_02

ğŸ“ æ‘˜è¦:
è®¨è®ºäº† FP-Enhancement é¡¹ç›®çš„å®éªŒæ–¹æ¡ˆï¼Œç¡®è®¤ç”±å¼€å‘éƒ¨é—¨æ¨è¿›...

ğŸ”‘ å…³é”®è¦ç‚¹:
  â€¢ å®éªŒæ–¹æ¡ˆç”±å¼€å‘éƒ¨é—¨æ¨è¿›ï¼Œé¢„è®¡ä¸‹å‘¨ä¸€å‡ºææ–™
  â€¢ æœåŠ¡ç«¯å½’å¹¶ + IP é«˜æƒé‡æ–¹å‘å·²ç¡®è®¤
  â€¢ ...

ğŸ“‹ å¾…åŠ:
  â€¢ [å¼€å‘éƒ¨é—¨] 3/2 å‰æäº¤å®éªŒæŠ¥å‘Š
  â€¢ [ipieces] è·Ÿè¿›å®éªŒç»“æœ

æ“ä½œ: [a]ç¡®è®¤ [e]ç¼–è¾‘ [s]è·³è¿‡ [d]ä¸¢å¼ƒ [v]æŸ¥çœ‹åŸæ–‡ [q]é€€å‡º >
```

### 2.8 å½’æ¡£ (`archiver/`)

æœ¬åœ°å½’æ¡£ï¼š

```
data/archive/
â””â”€â”€ 2026-02-26/
    â”œâ”€â”€ 001-meeting-fp-enhancementè®¨è®º.md
    â”œâ”€â”€ 002-phone-ä¾›åº”å•†æ²Ÿé€š.md
    â””â”€â”€ 003-idea-äº§å“æ–¹å‘æ€è€ƒ.md
```

Obsidian å½’æ¡£ï¼ˆå†™å…¥ vault æŒ‡å®šç›®å½•ï¼‰ï¼š

```yaml
archive:
  obsidian:
    vault_path: /Users/m4006/.openclaw/workspace/opsidian
    base_dir: AudioJournal          # vault å†…çš„å½’æ¡£ç›®å½•
    template: |                     # å½’æ¡£æ¨¡æ¿
      ---
      date: {{date}}
      scene: {{scene}}
      duration: {{duration}}
      speakers: {{speakers}}
      tags: {{topics}}
      ---
      # {{title}}

      ## æ‘˜è¦
      {{summary}}

      ## å…³é”®è¦ç‚¹
      {{key_points}}

      ## å¾…åŠäº‹é¡¹
      {{action_items}}

      ## åŸå§‹è½¬å†™
      > {{raw_text}}
```

---

## 3. Pipeline ç¼–æ’

```python
class Pipeline:
    def __init__(self, config: Config):
        self.chunker = VADChunker(config.chunker)
        self.asr = ASRFactory.create(config.asr)
        self.segmenter = SilenceSegmenter(config.segmenter)
        self.classifier = SceneClassifier(config.classifier, llm)
        self.router = AnalyzerRouter(analyzers)
        self.archiver = ArchiverFactory.create(config.archive)

    async def process(self, audio_path: str) -> list[AnalysisResult]:
        # Step 0: éŸ³é¢‘é¢„åˆ‡åˆ†ï¼ˆé•¿å½•éŸ³ â†’ å¤šä¸ª chunkï¼‰
        chunks = self.chunker.split(audio_path)

        all_results = []
        for chunk in chunks:
            # Step 1: ASR è½¬å†™ï¼ˆå«è¯´è¯äººè¯†åˆ«ï¼‰
            utterances = self.asr.transcribe(chunk.path)

            # Step 2: æ–‡æœ¬åˆ†æ®µ
            segments = self.segmenter.segment(utterances, chunk.path)

            # Step 3: åœºæ™¯åˆ†ç±»
            classified = [await self.classifier.classify(seg) for seg in segments]

            # Step 4: åœºæ™¯åˆ†æï¼ˆå¯å¹¶å‘ï¼‰
            results = await asyncio.gather(*[
                self.router.route(seg) for seg in classified
            ])
            all_results.extend(results)

        # Step 5: è‡ªåŠ¨å½’æ¡£ï¼ˆæ— éœ€äººå·¥ç¡®è®¤ï¼‰
        archived = self.archiver.archive_all(all_results)
        logger.info(f"å·²è‡ªåŠ¨å½’æ¡£ {len(archived)} æ¡ç»“æœ")

        return all_results


class FileWatcher:
    """ç›‘å¬ç›®å½•ï¼Œæ£€æµ‹æ–°éŸ³é¢‘æ–‡ä»¶å¹¶è§¦å‘ Pipeline"""
    def __init__(self, config: Config, pipeline: Pipeline):
        self.watch_dir = config.paths.inbox
        self.pipeline = pipeline

    def start(self):
        """å¯åŠ¨æ–‡ä»¶ç›‘å¬æœåŠ¡"""
        observer = Observer()
        handler = AudioFileHandler(self.pipeline)
        observer.schedule(handler, self.watch_dir, recursive=False)
        observer.start()
        logger.info(f"ç›‘å¬ç›®å½•: {self.watch_dir}")

class AudioFileHandler(FileSystemEventHandler):
    def on_created(self, event):
        if event.src_path.endswith('.wav'):
            # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
            self._wait_stable(event.src_path)
            asyncio.run(self.pipeline.process(event.src_path))
```

---

## 4. CLI å‘½ä»¤è®¾è®¡

```bash
# æœåŠ¡ç®¡ç†
audio-journal start                      # å¯åŠ¨æ–‡ä»¶ç›‘å¬æœåŠ¡ï¼ˆå‰å°ï¼‰
audio-journal start -d                   # åå°å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼
audio-journal stop                       # åœæ­¢æœåŠ¡

# æŸ¥çœ‹çŠ¶æ€
audio-journal status                     # æœåŠ¡çŠ¶æ€ + å¤„ç†ç»Ÿè®¡

# æŸ¥çœ‹å½’æ¡£ç»“æœ
audio-journal list                       # åˆ—å‡ºæœ€è¿‘å½’æ¡£
audio-journal list --date 2026-02-26     # æŒ‰æ—¥æœŸ
audio-journal list --scene meeting       # æŒ‰åœºæ™¯
audio-journal show <id>                  # æŸ¥çœ‹æŸæ¡è¯¦æƒ…

# é‡æ–°å¤„ç†
audio-journal reprocess <id>             # é‡æ–°åˆ†ææŸæ¡ï¼ˆç”¨æœ€æ–° promptï¼‰
audio-journal reprocess --date 2026-02-26  # é‡æ–°å¤„ç†æŸå¤©å…¨éƒ¨

# æ‰‹åŠ¨è§¦å‘ï¼ˆä¸ä¾èµ– watcherï¼‰
audio-journal process <file.wav>         # æ‰‹åŠ¨å¤„ç†æŒ‡å®šæ–‡ä»¶

# é…ç½®ç®¡ç†
audio-journal config show                # æ˜¾ç¤ºå½“å‰é…ç½®
audio-journal config set llm.provider zai  # ä¿®æ”¹é…ç½®
```

---

## 5. é…ç½®æ–‡ä»¶ (`config.yaml`)

```yaml
# ASR é…ç½®
asr:
  engine: funasr
  model: paraformer-zh
  vad_model: fsmn-vad       # è¯­éŸ³æ´»åŠ¨æ£€æµ‹
  punc_model: ct-punc       # æ ‡ç‚¹æ¢å¤
  spk_model: cam++          # è¯´è¯äººè¯†åˆ«
  device: mps
  batch_size: 4

# éŸ³é¢‘é¢„åˆ‡åˆ†é…ç½®
chunker:
  min_silence_gap: 30       # ç§’ï¼Œé¢„åˆ‡åˆ†é™éŸ³é˜ˆå€¼ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
  max_chunk_duration: 14400 # ç§’ï¼Œå•ä¸ª chunk æœ€é•¿ 4 å°æ—¶ï¼ˆè¦†ç›–é•¿ä¼šè®®åœºæ™¯ï¼‰
  min_chunk_duration: 60    # ç§’ï¼Œä½äº 1 åˆ†é’Ÿçš„ chunk åˆå¹¶åˆ°ç›¸é‚» chunk
  parallel: true            # æ˜¯å¦å¹¶è¡Œå¤„ç†å¤šä¸ª chunk
  max_workers: 4            # å¹¶è¡Œå¤„ç†çš„æœ€å¤§ worker æ•°

# åˆ†æ®µé…ç½®
segmenter:
  min_silence_gap: 30       # ç§’ï¼Œé™éŸ³åˆ†æ®µé˜ˆå€¼
  max_segment_duration: 1800 # ç§’ï¼Œå•æ®µæœ€é•¿
  min_segment_duration: 10   # ç§’ï¼Œæœ€çŸ­æœ‰æ•ˆæ®µ

# LLM é…ç½®
llm:
  provider: deepseek  # openai | deepseek | zai
  model: deepseek-chat
  api_key_env: DEEPSEEK_API_KEY  # z.ai æ¨è ZHIPUAI_API_KEY
  # base_url: https://api.deepseek.com/v1  # å¯é€‰ï¼šä¸å¡«ä½¿ç”¨å†…ç½®é»˜è®¤å€¼ï¼›zai é»˜è®¤ https://open.bigmodel.cn/api/paas/v4/
  temperature: 0.3
  overrides:
    classifier:
      provider: deepseek
      model: deepseek-chat
    analyzer:
      provider: zai
      model: glm-4-plus
      api_key_env: ZHIPUAI_API_KEY

# åœºæ™¯é…ç½®
scenes:
  - meeting
  - business
  - idea
  - learning
  - phone
  - chat

# å½’æ¡£é…ç½®
archive:
  default_target: local
  local:
    base_dir: ./data/archive
  obsidian:
    vault_path: /path/to/obsidian/vault
    base_dir: AudioJournal

# è·¯å¾„é…ç½®
paths:
  inbox: ./data/inbox
  processing: ./data/processing
  transcripts: ./data/transcripts
  analysis: ./data/analysis
  prompts: ./prompts

# æ–‡ä»¶ç›‘å¬é…ç½®
watcher:
  watch_dir: ./data/inbox       # ç›‘å¬ç›®å½•
  patterns: ["*.wav"]           # ç›‘å¬çš„æ–‡ä»¶ç±»å‹
  stable_seconds: 5             # æ–‡ä»¶å†™å…¥ç¨³å®šç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
  daemon: false                 # æ˜¯å¦ä»¥å®ˆæŠ¤è¿›ç¨‹è¿è¡Œ
```

---

## 6. å®ç°è®¡åˆ’ï¼ˆåˆ†é˜¶æ®µï¼‰

### Phase 1: MVP â€” æ ¸å¿ƒæµç¨‹è·‘é€š
1. é¡¹ç›®è„šæ‰‹æ¶ï¼ˆpyproject.toml, ç›®å½•ç»“æ„, config åŠ è½½ï¼‰
2. æ•°æ®æ¨¡å‹å®šä¹‰ï¼ˆPydantic schemasï¼‰
3. LLM æŠ½è±¡å±‚ï¼ˆè‡³å°‘å®ç°ä¸€ä¸ª providerï¼‰
4. éŸ³é¢‘é¢„åˆ‡åˆ†å™¨ï¼ˆVAD Chunkerï¼Œæ”¯æŒå¯é…ç½®é™éŸ³é˜ˆå€¼ï¼‰
5. ASR æ¨¡å—ï¼ˆå…ˆå®ç°ä¸€ä¸ªå¼•æ“ï¼‰
6. åˆ†æ®µå™¨
7. åœºæ™¯åˆ†ç±»å™¨
8. ä¸€ä¸ªåœºæ™¯åˆ†æå™¨ï¼ˆå…ˆåš meetingï¼‰
9. è‡ªåŠ¨å½’æ¡£ï¼ˆæœ¬åœ°ï¼‰
10. æ–‡ä»¶ç›‘å¬æœåŠ¡ï¼ˆwatchdogï¼‰
11. Pipeline ç¼–æ’ + `audio-journal start` å‘½ä»¤
12. ç®¡ç† CLIï¼ˆstatus/list/showï¼‰

### Phase 2: å®Œå–„åœºæ™¯ + å½’æ¡£
13. å‰©ä½™ 5 ä¸ªåœºæ™¯åˆ†æå™¨
14. é—²èŠä»·å€¼æ£€æµ‹ï¼ˆäºŒå±‚åˆ†ç±»ï¼‰
15. Obsidian å½’æ¡£
16. ç¬¬äºŒä¸ª ASR å¼•æ“
17. ç¬¬äºŒä¸ª LLM provider
18. reprocess å‘½ä»¤ï¼ˆç”¨æœ€æ–° prompt é‡æ–°åˆ†æï¼‰

### Phase 3: ä¼˜åŒ–ä½“éªŒ
19. é•¿éŸ³é¢‘ chunk å¹¶è¡Œå¤„ç†
20. å¤„ç†è¿›åº¦æ—¥å¿—
21. åˆ†æç»“æœç¼“å­˜ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
22. è¯´è¯äººæ ‡æ³¨è®°å¿†ï¼ˆSPEAKER_01 = å¼ ä¸‰ï¼‰
23. è·¨ chunk è¯´è¯äººå…³è”ï¼ˆå£°çº¹åµŒå…¥èšç±»ï¼‰
24. å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ + å¼€æœºè‡ªå¯
